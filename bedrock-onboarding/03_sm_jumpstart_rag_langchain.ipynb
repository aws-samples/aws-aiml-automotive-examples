{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0463b082-6f0a-4ffe-9fa9-d1075cea18d4",
   "metadata": {},
   "source": [
    "# Build a Q&A application with SageMaker Jumpstart, Langchain and FAISS index\n",
    "\n",
    "This notebook explains steps requried to build a Question & Answer application using Retrieval Augmented Generation (RAG) architecture.\n",
    "RAG combines the power of pre-trained LLMs with information retrieval - enabling more accurate and context-aware responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1b059e4-443a-4fa5-a9d7-b02f3763615e",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e1867-409a-43bf-bc07-83a67599216c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install langchain --upgrade\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4a8ff-8b50-47da-a6c7-c7b0cb206a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c05900-664c-4747-a4bf-8af770dafa09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3d4b94d-3d83-40aa-8a92-03435f7f4776",
   "metadata": {},
   "source": [
    "## Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8069f-83c0-4517-aec9-f7fe28440adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart Kernel after the installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "489eb77a-b0b4-4339-9eeb-e81dabcdeea2",
   "metadata": {},
   "source": [
    "## Setup depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20315fba-ef88-4a7a-b859-eb82cac80559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check Python version is greater than 3.8 which is required by Langchain if you want to use Langchain\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c9b4a-95ec-4879-b13e-d5363314e143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be7dc4-bef3-4223-9f0d-50f5ba707a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6e9ec-46a2-4e25-98fd-3231c729c859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54c046c-8775-4251-9836-3a1b55cd7e9d",
   "metadata": {},
   "source": [
    "## Deploy SageMaker Jumpstart model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2b0f4-34a9-40aa-8bcf-a4c67e87cce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, model_uris, script_uris,instance_types, hyperparameters\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "sm_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1bc7f-427f-4415-a213-5ba6a4d1308f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sm_llm_model_id = \"huggingface-textgeneration1-bloomz-7b1-fp16\" #\"huggingface-text2text-flan-ul2-bf16\" #\"huggingface-textgeneration1-bloomz-7b1-fp16\" #\"huggingface-text2text-flan-t5-xxl\"\n",
    "#sm_llm_model_id = \"huggingface-text2text-flan-ul2-bf16\" #\"huggingface-textgeneration1-bloomz-7b1-fp16\" #\"huggingface-text2text-flan-t5-xxl\"\n",
    "model_id = \"huggingface-text2text-flan-t5-xl\"\n",
    "model_version = \"*\"\n",
    "endpoint_name = f'sm-jumpstart-langchain-{model_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cacb01-5607-427e-b46c-b5b3214ce6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference instance type for the specified model.\n",
    "instance_type = instance_types.retrieve_default(\n",
    "    model_id=model_id, model_version=model_version, scope=\"inference\"\n",
    ")\n",
    "#instance_type = 'ml.g5.24xlarge'\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1da99e-bbd3-4e42-b61b-0b782735a03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\"MMS_DEFAULT_WORKERS_PER_MODEL\": \"1\"}\n",
    "\n",
    "# Get Image URI\n",
    "image_uri = image_uris.retrieve(region=aws_region,framework=None,image_scope=\"inference\",model_id=model_id,model_version=model_version,instance_type=instance_type)\n",
    "\n",
    "# Get model uri.\n",
    "model_uri = model_uris.retrieve(model_id=model_id,model_version=model_version,model_scope=\"inference\" )\n",
    "\n",
    "#Create Model\n",
    "model = Model(image_uri=image_uri,model_data=model_uri,role=aws_role,predictor_cls=Predictor,name=endpoint_name,env=env)\n",
    "\n",
    "print(f'Image URI {image_uri}')\n",
    "print(f'Model URI {model_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f8a07-4c25-48fc-af7e-8c7460c91043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Deploy the model\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df427bc-eebe-4412-a135-a874fb042947",
   "metadata": {},
   "source": [
    "## Perform document pre-processing\n",
    "Load the documents, perform clean-up of the text before generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ade1e6-d10e-4b39-bc34-886f61145e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter,NLTKTextSplitter\n",
    "import pathlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c14cff-5bb1-4538-b11a-cc7920585697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "index_path = 'faiss_indices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c364185-5ee8-49bd-8390-4c349e6e3422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your directory containing PDFs here\n",
    "index_name = 'firetv'\n",
    "directory = f'pdfs/{index_name}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ee5746-032f-44df-84c6-0335b2148166",
   "metadata": {},
   "source": [
    "If you have previously generated embeddings and saved the document embeddings locally, skip the following section and go to Generate Embeddings section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94faf8-e3cb-48cd-88d6-9a7a327b6e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    #separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \",\", \"\"],\n",
    "    length_function=len,\n",
    "    keep_separator=False,\n",
    "    add_start_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11839f-a854-4fc5-9259-cb8abfe7b81e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_documents = [os.path.join(directory, filename) for filename in os.listdir(directory)]\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a157ee-8c76-49ef-8203-2b7ef03f6ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain_documents = []\n",
    "for document in pdf_documents:\n",
    "    loader = PyPDFLoader(document)\n",
    "    data = loader.load()\n",
    "    langchain_documents.extend(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bea2e-ca2b-4150-ad27-da5ea62e71d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"loaded document pages: \", len(langchain_documents))\n",
    "print(\"Splitting all documents\")\n",
    "split_docs = text_splitter.split_documents(langchain_documents)\n",
    "print(\"Num split pages: \", len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68869a-d8ea-42bd-b696-69fdbb8794ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003c5b7-2f8d-4ce4-9e30-89c873b4f515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "for d in split_docs:\n",
    "    text = d.page_content\n",
    "    text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "    text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip()) # Remove newlines \n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "    text = re.sub(r'[/X]', \"\", text)     #Remove hexadecimal chars\n",
    "    text = re.sub(r\"(\\\\u[0-9A-Fa-f]+)\",\" \",text) #Remove other speciail characters\n",
    "    d.page_content = text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ae50b01-0f7f-41fa-b3fa-3ecc630d5747",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "Use an embeddings model to generate embeddings of the cleaned-up doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ea739ef-f75b-4aa5-9bbb-cb4ae137639a",
   "metadata": {},
   "source": [
    "### Option 1- Bedrock Titan Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b13d0-347e-4819-80c3-5e0f3a6bf752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "studio_region = sagemaker_session.boto_region_name \n",
    "bedrock = session.client(\"bedrock\", region_name=studio_region)\n",
    "\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "emb = BedrockEmbeddings(region_name =\"us-east-1\",model_id = \"amazon.titan-e1t-medium\")\n",
    "emb.model_kwargs = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7afbaff8-568a-429c-b19f-fb9092484466",
   "metadata": {},
   "source": [
    "### Option 2- Huggingface Embeddings - Requires sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01159685-f3e0-4d87-a8bb-ac942a0d95a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "emb = HuggingFaceEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35d6a4c9-cd67-45a1-9d3c-1ace18e26cf9",
   "metadata": {},
   "source": [
    "## Setup local Vector store - FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea489f2-7133-4037-b81b-8a36b36da3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Embed and create vector index\")\n",
    "db = FAISS.from_documents(split_docs, embedding=emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6cbdb61-8740-422f-adff-443dcfaa1f90",
   "metadata": {},
   "source": [
    "### Save the indices locally as a file\n",
    "If you have already saved the indices, move to Load from local file cache section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82059e-6097-4da6-b0c1-1e75ba8113f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save the index created locally')\n",
    "pathlib.Path(index_path).mkdir(parents=True, exist_ok=True)\n",
    "db.save_local(folder_path=index_path, index_name= index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac2aded-5d4c-4ba6-ba57-90055270edbe",
   "metadata": {},
   "source": [
    "### Load from local file cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d13a5-395b-4b54-ac9d-ea23b8ec5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Check if load local works properly\n",
    "db_local = FAISS.load_local(folder_path=index_path, embeddings=emb, index_name=index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f500810-861e-4cca-b0cf-ea87fc878118",
   "metadata": {},
   "source": [
    "### Perform a similarity search and get top 3 matching docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343462fe-f118-4f2c-97a5-fa7d8f81360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to setup Parental controls?\"\n",
    "docs = db_local.similarity_search(query, k=3)\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6884175-f9d0-4ed5-8cf2-1f4c19508eec",
   "metadata": {},
   "source": [
    "## Access SageMaker Jumpstart hosted LLM with the context from vecor store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19664b2a-aaa5-4d17-b4e7-62f77025016d",
   "metadata": {},
   "source": [
    "### Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c3966-5237-4092-9bce-f2c81b69e6d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "\n",
    "temperature=1\n",
    "max_length=500\n",
    "top_p=1\n",
    "top_k=50\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"generated_texts\"][0]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name, \n",
    "        region_name=aws_region, \n",
    "        model_kwargs={\"temperature\":temperature, \"max_length\": max_length, \"top_p\": top_p, \"top_k\":top_k},\n",
    "        content_handler=content_handler)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f964b28c-0a25-40e9-9610-daeeab30d295",
   "metadata": {},
   "source": [
    "### Method 1- Simple query with  Vector store wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8818c2-6d8f-4835-90b8-c70a5d2325a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "wrapper_store = VectorStoreIndexWrapper(vectorstore=db_local)\n",
    "\n",
    "response = wrapper_store.query(question=query, llm=llm)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78ef8bec-abf8-4e9f-b9e5-15312fbea28b",
   "metadata": {},
   "source": [
    "### Method 2- Query with chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca929068-513e-481b-a083-0dda1a91b441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "documents = db_local.similarity_search(query=query, k=5)\n",
    "print(chain.run(input_documents=documents, question=query))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b8109fa-9901-44de-8c2c-c2369f3ef77f",
   "metadata": {},
   "source": [
    "### Method 3- Query with Prompt template (Provides prompt customization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26733b78-347a-4d91-acf6-3131c679e010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end. \n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c1db0-05e0-4e6c-95c6-abb22a5b4b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db_local.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "response = qa({'query':query})\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e0267-f2b4-45f8-b99a-5b848e1e3143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response['source_documents']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a552bb0a-79c3-4a3e-89aa-12dde3b392c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement RAG architecture with Kendra Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ef8cc-b0a2-48a2-ae4a-92785b082916",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendra_index = \"\" #Provide Kendra index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee8f42-7d3f-4842-983b-42cf69d24dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "kendra = boto3.client('kendra')\n",
    "response = kendra.retrieve(IndexId=kendra_index,QueryText=query)\n",
    "docs = [Document(page_content = r['Content']) for r in response['ResultItems']]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07489ecb-35a1-46c1-a082-1b3f6a7f4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "print(chain.run(input_documents=docs, question=query))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b42103a-8cbd-437a-a772-f491dd0d1a5f",
   "metadata": {},
   "source": [
    "## Clean-Up (Optional)\n",
    "Delete the model and the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31d938-e569-4d28-9607-4fa16a74130f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66565237-0b2d-4faa-8fea-59dd57ad16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
