{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7786875a-b67a-49d1-acde-34e840b72dc7",
   "metadata": {},
   "source": [
    "# Continued Pre-training Amazon Titan Text G1 Express with Bedrock\n",
    "\n",
    "This notebook provides steps requried to customize a model with continued pre-training. Using Amazon Bedrock you can perform continued pre-training to adapt the model with your domain knowledge that's not present when the base model was trained. You can train a model with your domain data (business documents, or other business corpus). You can continue to improve the model by retraining the model with more unlabeled data as it becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf95fd7-cd84-4454-baa0-395f8ef54c4d",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995ca55-aadf-44b6-af87-03cd7dafc6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check Python version is greater than 3.8 which is required by Langchain if you want to use Langchain\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a5245-e7d0-4547-bf61-8ab5f3a0eee9",
   "metadata": {},
   "source": [
    "## Install the SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af668381-7280-4ddd-ab93-72ab64eb250e",
   "metadata": {
    "tags": []
   },
   "source": [
    "NOTE:\n",
    "This notebook requires Bedrock Python SDK. Install Bedrock SDK if you haven't done yet. Refer to 00_bedrock_onboarding.ipynb notebook for steps to install and uninstall previous version if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676e528-dbe0-4c5a-a7b2-dada29661961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906efc69-edd4-4039-9f8a-f11319ba6041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b621751-99e1-4252-b878-4364b8fdab2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create IAM Role and assign Permissions\n",
    "\n",
    "We need to create two roles\n",
    "\n",
    "Role A- Notebook execution\n",
    "--\n",
    "This notebook requires permissions to invoke Bedrock service. Ensure to add a policy to the role listed above similar to\n",
    "    \n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"Bedrock\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock:*\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Role B- Data access\n",
    "--\n",
    "To start the continued pre-training job, the role created above will pass execution to another IAM role that has access to continued pre-training job. Create a role that has following Trust relationship\n",
    "\n",
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"bedrock.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\",\n",
    "      \"Condition\": {\n",
    "        \"StringEquals\": {\n",
    "          \"aws:SourceAccount\": \"<account>\"\n",
    "        },\n",
    "        \"ArnEquals\": {\n",
    "          \"aws:SourceArn\": \"arn:aws:bedrock:<region>:<account>:model-customization-job/*\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "The role created above needs to have permissions to S3 bucket where the training & validation datasets are located and access to S3 location where continued pre-training job output will be written\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:ListObjects\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::<train_set_bucket>\",\n",
    "                \"arn:aws:s3:::<train_set_bucket>/*\",\n",
    "                \"arn:aws:s3:::<test_set_bucket>\",\n",
    "                \"arn:aws:s3:::<test_set_bucket>/*\",\n",
    "                \"arn:aws:s3:::<job_output_bucket>\",\n",
    "                \"arn:aws:s3:::<job_output_bucket>/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Also ensure Role A has permissions to pass IAM Role to Role B. This needs to be defined as an IAM policy similar to below\n",
    "\n",
    "```\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"iam:GetRole\",\n",
    "\t\t\t\t\"iam:PassRole\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Resource\": \"arn:aws:iam::<account>:role/*\"\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b8655-71c7-4af3-a954-085b5e80a0a9",
   "metadata": {},
   "source": [
    "## Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0af31-edda-4d3f-804c-4463d9571b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d520a2-dcfc-4559-8899-1b7feee94f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "studio_region = sagemaker_session.boto_region_name \n",
    "#sagemaker_session.get_caller_identity_arn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a699367-f622-4a10-8683-954af9f3adbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ecde1195-5a74-4afe-8a44-bbd4ef99d911',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 23 Jan 2024 15:26:24 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '17086',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'ecde1195-5a74-4afe-8a44-bbd4ef99d911'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large',\n",
       "   'modelName': 'Titan Text Large',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02',\n",
       "   'modelName': 'Titan Text Embeddings v2',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelId': 'amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1',\n",
       "   'modelId': 'amazon.titan-text-lite-v1',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'modelId': 'amazon.titan-text-express-v1:0:8k',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelId': 'amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "   'modelId': 'amazon.titan-embed-image-v1:0',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-image-v1',\n",
       "   'modelId': 'amazon.titan-embed-image-v1',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-image-generator-v1:0',\n",
       "   'modelId': 'amazon.titan-image-generator-v1:0',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-image-generator-v1',\n",
       "   'modelId': 'amazon.titan-image-generator-v1',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v1:0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1:0',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v1',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct',\n",
       "   'modelName': 'J2 Grande Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct',\n",
       "   'modelName': 'J2 Jumbo Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1:2:100k',\n",
       "   'modelId': 'anthropic.claude-instant-v1:2:100k',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'LEGACY'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:0:18k',\n",
       "   'modelId': 'anthropic.claude-v2:0:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:0:100k',\n",
       "   'modelId': 'anthropic.claude-v2:0:100k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1:18k',\n",
       "   'modelId': 'anthropic.claude-v2:1:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1:200k',\n",
       "   'modelId': 'anthropic.claude-v2:1:200k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1',\n",
       "   'modelId': 'anthropic.claude-v2:1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-text-v14:7:4k',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-light-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-light-text-v14:7:4k',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-light-text-v14',\n",
       "   'modelId': 'cohere.command-light-text-v14',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-english-v3',\n",
       "   'modelId': 'cohere.embed-english-v3',\n",
       "   'modelName': 'Embed English',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-multilingual-v3',\n",
       "   'modelId': 'cohere.embed-multilingual-v3',\n",
       "   'modelName': 'Embed Multilingual',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-chat-v1',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-chat-v1',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-v1',\n",
       "   'modelId': 'meta.llama2-13b-v1',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-v1',\n",
       "   'modelId': 'meta.llama2-70b-v1',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if basic commands work with bedrock client\n",
    "bedrock = boto3.client('bedrock')\n",
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a247ef-920e-4385-b680-8e2add6d4017",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "In this step, we will use [SQUAD dataset](https://arxiv.org/abs/1606.05250) for continued pre-training. This dataset has a list of questions under different categories (title). We will filter for a category and use the filtered set for continued pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a7208a-fd9f-46a1-8fee-a04882a28f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5113c4-8941-419c-8cf6-41552caab24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62114b3f-55aa-4244-9728-1d49364ef6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "     num_rows: 225\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "     num_rows: 25\n",
       " }))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = 'Solar_energy'\n",
    "raw_train_set = raw_datasets['train']\n",
    "raw_test_set = raw_datasets['validation']\n",
    "train_set = raw_train_set.filter(lambda x: x['title'] == category)\n",
    "test_set = raw_test_set.filter(lambda x: x['title'] == category)\n",
    "\n",
    "if len(test_set) == 0: #If there is no test data set available, split the train set for this\n",
    "    split_set = train_set.train_test_split(test_size=0.1)\n",
    "    train_set,test_set = split_set['train'],split_set['test']\n",
    "\n",
    "train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55132d-4716-4899-81d4-3f5e04cbabc2",
   "metadata": {},
   "source": [
    "## Prepare Training Dataset\n",
    "In this step, we will upload training data to an S3 bucket. Bedrock customization job expects training and validation data to be in JSONL format and there should be any new line character at the end of the file.\n",
    "We will convert the dataset downloaded into a JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b12f211-a267-4002-8fbb-ca24351958d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib , os, json\n",
    "continued_pretraining_dataset_path = 'data/continued-pretraining'\n",
    "pathlib.Path(continued_pretraining_dataset_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07437bed-11e0-405f-8cbd-743598dbea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jinja2\n",
    "\n",
    "env = jinja2.Environment(loader=jinja2.FileSystemLoader('templates'))\n",
    "squad_template = env.get_template('continued_pretraining.txt')\n",
    "\n",
    "def create_data_file(data,file_name):\n",
    "    data_len = len(data)\n",
    "    with open(file_name,'w') as f:\n",
    "        for i, item in enumerate(data):\n",
    "            c = item['context']\n",
    "            c = c.replace('\"','') #Remove any double quotes in context\n",
    "            jsonl = squad_template.render(context=c)\n",
    "            f.write(jsonl)\n",
    "            if i < (data_len -1):\n",
    "                f.write('\\n')\n",
    "    print(f'File {file_name} created with {data_len} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f93cd4-4d09-4878-b1e5-eeed45a243e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def split_s3_path(s3_uri):\n",
    "    parse_result = urlparse(s3_uri, allow_fragments=False)\n",
    "    return parse_result.netloc,parse_result.path.lstrip('/')\n",
    "\n",
    "def s3_csv_to_df(s3_uri):\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket, object_key = split_s3_path(s3_uri)\n",
    "    csv = s3.get_object(Bucket=bucket, Key=object_key)\n",
    "    csvs = csv['Body'].read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csvs),sep=',')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca3d3353-02f2-4371-a8fe-f84bf912890f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file_name = f'{continued_pretraining_dataset_path}/train_data.jsonl'\n",
    "test_file_name = f'{continued_pretraining_dataset_path}/test_data.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43a76bb-4237-4f85-a77d-72825c31f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/continued-pretraining/train_data.jsonl created with 225 rows\n",
      "File data/continued-pretraining/test_data.jsonl created with 25 rows\n"
     ]
    }
   ],
   "source": [
    "create_data_file(train_set,train_file_name)\n",
    "create_data_file(test_set,test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d614a3a-95ab-4209-92a8-f561220a11b4",
   "metadata": {},
   "source": [
    "### Upload the files created locally yo S3 and get the URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa006048-ab6d-4571-aac9-5111f96ebc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "continued_pretraining_prefix = 'bedrock_continued_pretraining'\n",
    "train_data_s3_path = sagemaker_session.upload_data(train_file_name, bucket=bucket, key_prefix=continued_pretraining_prefix)\n",
    "test_data_s3_path = sagemaker_session.upload_data(test_file_name, bucket=bucket, key_prefix=continued_pretraining_prefix)\n",
    "\n",
    "train_data_s3_path,test_data_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec63bb-145e-482a-a543-e119a758cb68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start the customization job\n",
    "We will prepare the inputs to the Continued pretraining (model customization job) and start the job.\n",
    "Please make sure you have provided necessary IAM permissions explained in previous steps before proceeding further.\n",
    "\n",
    "Besisdes the Hyperparameters, we define the names (Job name, Custom model name), attach tags to job and custom model for tracking purposes, location of Training and test set and the output path where the continued pre-training job would save the training & validaition metrics.  \n",
    "\n",
    "We can optionally supply VPC configuation to ensure calls from the continued pre-training job to fetch training/ validation data are routed through VPC/ Private Links to S3. You can define security groups to define access controls for the job.\n",
    "\n",
    "Continued pre-training job supports following Hyper parameters\n",
    "\n",
    "- Epochs\n",
    "- Batch size\n",
    "- Learning Rate\n",
    "- Learning rate warmup steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0747b-f360-422d-8687-2b8ddffa1be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "#Define Hyperparameters\n",
    "hyper_params = {\"epochCount\" : \"1\",\"batchSize\":\"1\", \"learningRate\": \"0.00005\",\"learningRateWarmupSteps\":\"0\"}\n",
    "\n",
    "#Define names (Job, Model)\n",
    "base_model = \"amazon.titan-text-express-v1\"\n",
    "client_token = str(uuid4())\n",
    "custom_model_name= category.lower() + '_pre_trained_model'\n",
    "job_name = f\"bedrock-cp-titan-{datetime.now().strftime('%Y%m-%d%H-%M%S')}\"\n",
    "\n",
    "#Define tahs for tracking purposes\n",
    "model_tags = [{\"key\": \"custom_model_type\",\"value\": category.lower()}]\n",
    "job_tags = [{\"key\": \"base_model_type\",\"value\": base_model.replace(\".\",\"-\")}]\n",
    "\n",
    "\n",
    "output_s3_path = f's3://{bucket}/{continued_pretraining_prefix}/output/'\n",
    "\n",
    "continued_pre_training_role = sagemaker_session.get_caller_identity_arn() \n",
    "#continued_pre_training_role = '' #Provide Role here\n",
    "\n",
    "#Optional Setup VPC configuration\n",
    "# vpc_config = {\n",
    "#     \"securityGroupIds\":[\"sg-1\",\"sg-2\"],\n",
    "#     \"subnetIds\":[\"subnet-a\", \"subnet-b\"]\n",
    "# }\n",
    "\n",
    "client_token, custom_model_name, job_name, continued_pre_training_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f917ea5-8276-459f-88fe-d2e75d1d1cc4",
   "metadata": {},
   "source": [
    "### Start the job using create_model_customization_job API\n",
    "NOTE: This might take upto 30 minutes to complete depending on the training and validation dataset and other hyperparameters like Epochs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21012cf8-b163-404d-9754-1dbb31d5c17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.create_model_customization_job(\n",
    "    customizationType=\"CONTINUED_PRE_TRAINING\",\n",
    "    baseModelIdentifier = base_model,\n",
    "    clientRequestToken = client_token,\n",
    "    customModelName = custom_model_name,\n",
    "    customModelTags = model_tags,\n",
    "    jobTags=job_tags, \n",
    "    hyperParameters = hyper_params,\n",
    "    jobName=job_name,\n",
    "    outputDataConfig = {\"s3Uri\": output_s3_path},\n",
    "    trainingDataConfig = {\"s3Uri\" : train_data_s3_path},\n",
    "    #validationDataConfig =  {\"validators\": [ {\"s3Uri\": test_data_s3_path}]},\n",
    "    roleArn = continued_pre_training_role\n",
    "    #vpcConfig = vpc_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba4b623-4fe5-4588-9a78-fa5e3868304b",
   "metadata": {},
   "source": [
    "## Monitor the Continued Pre-training job\n",
    "Once the job is submitted we will get the Job ARN. We will be able to monitor the job with APIs list_model_customization_jobs & list_model_customization_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc7ed1-95ed-4aa7-98f3-ea9423d3fdd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.list_model_customization_jobs(nameContains=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39b948-10e1-45a3-a6e1-62a493a986f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#job_name = 'bedrock-titan-202308-2316-5550'\n",
    "job_detail = bedrock.get_model_customization_job(jobIdentifier=job_name)\n",
    "job_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930fcf2-b871-4d75-b45d-a8af1bffebe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_detail['status'], job_detail['jobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4097178-0179-4661-a8bf-139277af0ea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stop Model customization job (Optional)\n",
    "We can stop a model customization job in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927da046-b610-47d2-b545-103105c68080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optional- Uncomment to stop the job\n",
    "\n",
    "#stop_model_customization_job(jobIdentifier=job_detail['jobArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc597daf-e876-4446-bdc7-be83941dec7f",
   "metadata": {},
   "source": [
    "## View Training and Validation Metrics\n",
    "Wait until the status of the job changes to \"Completed\" before proceeding further\n",
    "In this step we will view the Training and Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59f760-d319-4f9a-8080-6b31a89799b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_metrics_out_s3_prefix = f\"{job_detail['outputDataConfig']['s3Uri']}model-customization-job-{job_detail['jobArn'].split('/')[-1]}\"\n",
    "job_metrics_out_s3_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf58ea3-bbde-4d6d-bd08-aee592b1920c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Print Step wise training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9ea32-9166-4d81-b7a5-ac10f9afaf43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "training_metrics_csv = f'{job_metrics_out_s3_prefix}/training_artifacts/step_wise_training_metrics.csv'\n",
    "train_metrics_df = s3_csv_to_df(training_metrics_csv)\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1384aa1-1708-444c-bcbd-d7a901211da2",
   "metadata": {},
   "source": [
    "### Print Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d3618-e5fc-4064-b1d2-36577c59a238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_metrics_csv = f'{job_metrics_out_s3_prefix}/validation_artifacts/post_fine_tuning_validation/validation/validation_metrics.csv'\n",
    "validation_metrics_df = s3_csv_to_df(validation_metrics_csv)\n",
    "validation_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a28ec-d17d-40f9-a983-727e847dfc4a",
   "metadata": {},
   "source": [
    "## List Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda2e97-8902-4cd9-a3c9-47d686ea35e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.list_custom_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1670747-3d10-44db-bec0-57c96d0c29b0",
   "metadata": {},
   "source": [
    "## Query custom model activation status\n",
    "In this step we will check the activation status of the model and check if it is ready for taking real-time inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294729d8-ce0c-489c-b6e8-fafb1af614b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = bedrock.get_custom_model(modelIdentifier=custom_model_name)\n",
    "custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fafc14-65e5-4a16-b1f7-aadafcdcb255",
   "metadata": {},
   "source": [
    "## Invoke Custom Model\n",
    "In this step we will invoke teh custom model trained with the Domain specific data. We will select a random item from the test set to get results.\n",
    "NOTE: Wait until the model is \"ACTIVE\" in the real time inference status. It might take upto 30 minutes for the model to become active (depending on volume of test and training datasets).\n",
    "\n",
    "Amazon Bedrock allows you to run inference on custom models by purchasing provisioned throughput. This guarantees a consistent level of throughput in exchange for a term commitment. You specify the number of model units needed to meet your applicationâ€™s performance needs. For evaluating custom models initially, you can purchase provisioned throughput hourly with no long-term commitment. With no commitment, a quota of one model unit is available per provisioned throughput. You can create up to two provisioned throughputs per account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1659661-38d3-4bbd-95a2-bf4fbef46650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "item_no = random.randint(0,len(test_set) - 1)\n",
    "test_item = test_set[item_no]\n",
    "test_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15708429-b533-44f3-80c2-437d19ff09ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "prompt_template = \"Given the context below, answer the specified question. The answer should be extracted directly from the context verbatim. CONTEXT: {context} QUESTION: {question}\"\n",
    "\n",
    "prompt = prompt_template.format(context=test_item['context'],question=test_item['question'])\n",
    "\n",
    "body = json.dumps({\"inputText\": prompt})\n",
    "modelId = custom_model_name\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime' )\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"results\")[0].get(\"outputText\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ef512-cb09-4a54-aed1-383aadf0c339",
   "metadata": {},
   "source": [
    "## Delete Custom Model (Optional)\n",
    "We can delete the custom model created above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa90e00-7f78-437c-aec4-ed85c205d58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optional. Uncomment below line to remove the custom model created\n",
    "#bedrock.delete_custom_model(modelIdentifier = custom_model['modelArn'])"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
